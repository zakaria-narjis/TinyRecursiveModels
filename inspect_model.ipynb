{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ae6352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL LOADED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "Model Configuration:\n",
      "  H_cycles: 3\n",
      "  H_layers: 0\n",
      "  L_cycles: 6\n",
      "  L_layers: 2\n",
      "  expansion: 4\n",
      "  forward_dtype: bfloat16\n",
      "  halt_exploration_prob: 0.1\n",
      "  halt_max_steps: 16\n",
      "  hidden_size: 512\n",
      "  mlp_t: True\n",
      "  no_ACT_continue: True\n",
      "  num_heads: 8\n",
      "  pos_encodings: none\n",
      "  puzzle_emb_len: 16\n",
      "  puzzle_emb_ndim: 512\n",
      "  causal: False\n",
      "  vocab_size: 11\n",
      "  seq_len: 81\n",
      "  num_puzzle_identifiers: 1\n",
      "  batch_size: 768\n",
      "\n",
      "Total parameters: 5,028,866\n",
      "Trainable parameters: 5,028,866\n",
      "\n",
      "================================================================================\n",
      "MODEL STRUCTURE (HIGH LEVEL)\n",
      "================================================================================\n",
      "ACTLossHead(\n",
      "  (model): TinyRecursiveReasoningModel_ACTV1(\n",
      "    (inner): TinyRecursiveReasoningModel_ACTV1_Inner(\n",
      "      (embed_tokens): CastedEmbedding()\n",
      "      (lm_head): CastedLinear()\n",
      "      (q_head): CastedLinear()\n",
      "      (puzzle_emb): CastedSparseEmbedding()\n",
      "      (L_level): TinyRecursiveReasoningModel_ACTV1ReasoningModule(\n",
      "        (layers): ModuleList(\n",
      "          (0-1): 2 x TinyRecursiveReasoningModel_ACTV1Block(\n",
      "            (mlp_t): SwiGLU(\n",
      "              (gate_up_proj): CastedLinear()\n",
      "              (down_proj): CastedLinear()\n",
      "            )\n",
      "            (mlp): SwiGLU(\n",
      "              (gate_up_proj): CastedLinear()\n",
      "              (down_proj): CastedLinear()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "================================================================================\n",
      "INPUT/OUTPUT TENSOR SHAPES\n",
      "================================================================================\n",
      "\n",
      "Batch structure:\n",
      "  inputs: torch.Tensor of shape (1, 81)\n",
      "    - dtype: torch.int32 or torch.long\n",
      "    - values: token IDs in range [0, 10]\n",
      "\n",
      "  labels: torch.Tensor of shape (1, 81)\n",
      "    - dtype: torch.int32 or torch.long\n",
      "    - values: token IDs in range [0, 10] or -100 (ignore)\n",
      "\n",
      "  puzzle_identifiers: torch.Tensor of shape (1,)\n",
      "    - dtype: torch.int32 or torch.long\n",
      "    - values: puzzle IDs in range [0, 0]\n",
      "\n",
      "Output structure:\n",
      "  logits: torch.Tensor of shape (1, 81, 11)\n",
      "    - unnormalized logits for each token position\n",
      "\n",
      "================================================================================\n",
      "CREATING DUMMY BATCH FOR TESTING\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "READY FOR INSPECTION!\n",
      "================================================================================\n",
      "\n",
      "Available objects:\n",
      "  - model: the full model (ACTLossHead)\n",
      "  - model.model: the ACT wrapper\n",
      "  - model.model.inner: the inner transformer model\n",
      "  - full_config: the full training config\n",
      "  - model_cfg: the model config\n",
      "  - dummy_batch: a sample batch\n",
      "  - carry: the model's recurrent state\n",
      "  - preds: predictions from forward pass\n",
      "\n",
      "Useful inspection functions:\n",
      "  - inspect_model_structure(model): detailed layer breakdown\n",
      "  - inspect_state_dict(model): all parameter shapes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import yaml\n",
    "from typing import Dict, Any\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from utils.functions import load_model_class\n",
    "\n",
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "CHECKPOINT_PATH = \"/home/zakarianarjis/workspace/TinyRecursiveModels/checkpoints/Sudoku-extreme-1k-aug-1000-ACT-torch/pretrain_mlp_t_sudoku/step_65100\"\n",
    "CHECKPOINT_PATH = \"/home/zakarianarjis/workspace/TinyRecursiveModels/checkpoints/single_z/step_65100\"\n",
    "DATA_PATH = \"data/sudoku-extreme-1k-aug-1000\"  # Need this to get dataset metadata\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "def strip_compiled_prefix(state_dict):\n",
    "    \"\"\"Remove _orig_mod. prefix from compiled model state dict.\"\"\"\n",
    "    new_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        if key.startswith('_orig_mod.'):\n",
    "            new_key = key.replace('_orig_mod.', '')\n",
    "            new_state_dict[new_key] = value\n",
    "        else:\n",
    "            new_state_dict[key] = value\n",
    "    return new_state_dict\n",
    "\n",
    "def get_dataset_metadata(data_path, split=\"test\"):\n",
    "    \"\"\"Load dataset metadata without loading the full dataset.\"\"\"\n",
    "    import json\n",
    "    from dataset.common import PuzzleDatasetMetadata\n",
    "    \n",
    "    metadata_file = os.path.join(data_path, split, \"dataset.json\")\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = PuzzleDatasetMetadata(**json.load(f))\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def load_model(checkpoint_path, data_path=None, device=\"cuda\"):\n",
    "    \"\"\"Load model from checkpoint.\"\"\"\n",
    "    \n",
    "    # Load config\n",
    "    config_file = os.path.join(os.path.dirname(checkpoint_path), \"all_config.yaml\")\n",
    "    with open(config_file, \"r\") as f:\n",
    "        full_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Extract model config\n",
    "    arch_config = full_config[\"arch\"]\n",
    "    model_name = arch_config[\"name\"]\n",
    "    loss_config = arch_config[\"loss\"]\n",
    "    loss_name = loss_config[\"name\"]\n",
    "    \n",
    "    # Build model config\n",
    "    model_cfg = {k: v for k, v in arch_config.items() if k not in [\"name\", \"loss\"]}\n",
    "    model_cfg[\"causal\"] = False\n",
    "    \n",
    "    # Get dataset metadata if data_path provided, otherwise use defaults from config\n",
    "    if data_path is not None:\n",
    "        metadata = get_dataset_metadata(data_path)\n",
    "        model_cfg[\"vocab_size\"] = metadata.vocab_size\n",
    "        model_cfg[\"seq_len\"] = metadata.seq_len\n",
    "        model_cfg[\"num_puzzle_identifiers\"] = metadata.num_puzzle_identifiers\n",
    "        model_cfg[\"batch_size\"] = full_config.get(\"global_batch_size\", 64)\n",
    "    else:\n",
    "        # Try to infer from training config\n",
    "        train_data_path = full_config[\"data_paths\"][0]\n",
    "        if os.path.exists(train_data_path):\n",
    "            metadata = get_dataset_metadata(train_data_path, split=\"train\")\n",
    "            model_cfg[\"vocab_size\"] = metadata.vocab_size\n",
    "            model_cfg[\"seq_len\"] = metadata.seq_len\n",
    "            model_cfg[\"num_puzzle_identifiers\"] = metadata.num_puzzle_identifiers\n",
    "            model_cfg[\"batch_size\"] = full_config.get(\"global_batch_size\", 64)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot find dataset at {train_data_path}. Please provide data_path argument.\")\n",
    "    \n",
    "    # Load classes\n",
    "    model_cls = load_model_class(model_name)\n",
    "    loss_head_cls = load_model_class(loss_name)\n",
    "    loss_kwargs = {k: v for k, v in loss_config.items() if k != \"name\"}\n",
    "    \n",
    "    # Create model\n",
    "    with torch.device(device):\n",
    "        model = model_cls(model_cfg)\n",
    "        model = loss_head_cls(model, **loss_kwargs)\n",
    "        \n",
    "        # Load weights\n",
    "        state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "        state_dict = strip_compiled_prefix(state_dict)\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.eval()\n",
    "    \n",
    "    return model, full_config, model_cfg\n",
    "\n",
    "def inspect_model_structure(model):\n",
    "    \"\"\"Print detailed model structure.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DETAILED MODEL STRUCTURE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nLayer breakdown:\")\n",
    "    for name, module in model.named_modules():\n",
    "        if len(list(module.children())) == 0:  # Only leaf modules\n",
    "            num_params = sum(p.numel() for p in module.parameters())\n",
    "            if num_params > 0:\n",
    "                print(f\"  {name}: {module.__class__.__name__} ({num_params:,} params)\")\n",
    "\n",
    "def inspect_state_dict(model):\n",
    "    \"\"\"Print state dict keys and shapes.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MODEL STATE DICT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for name, param in model.state_dict().items():\n",
    "        print(f\"  {name}: {tuple(param.shape)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Load Model\n",
    "# ============================================================================\n",
    "\n",
    "model, full_config, model_cfg = load_model(CHECKPOINT_PATH, DATA_PATH)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL LOADED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Print config\n",
    "print(\"\\nModel Configuration:\")\n",
    "for key, value in model_cfg.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL STRUCTURE (HIGH LEVEL)\")\n",
    "print(\"=\" * 80)\n",
    "print(model)\n",
    "\n",
    "# ============================================================================\n",
    "# Input/Output Shapes\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INPUT/OUTPUT TENSOR SHAPES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = model_cfg[\"seq_len\"]\n",
    "vocab_size = model_cfg[\"vocab_size\"]\n",
    "num_puzzle_identifiers = model_cfg[\"num_puzzle_identifiers\"]\n",
    "\n",
    "print(f\"\\nBatch structure:\")\n",
    "print(f\"  inputs: torch.Tensor of shape ({batch_size}, {seq_len})\")\n",
    "print(f\"    - dtype: torch.int32 or torch.long\")\n",
    "print(f\"    - values: token IDs in range [0, {vocab_size - 1}]\")\n",
    "print(f\"\\n  labels: torch.Tensor of shape ({batch_size}, {seq_len})\")\n",
    "print(f\"    - dtype: torch.int32 or torch.long\")\n",
    "print(f\"    - values: token IDs in range [0, {vocab_size - 1}] or -100 (ignore)\")\n",
    "print(f\"\\n  puzzle_identifiers: torch.Tensor of shape ({batch_size},)\")\n",
    "print(f\"    - dtype: torch.int32 or torch.long\")\n",
    "print(f\"    - values: puzzle IDs in range [0, {num_puzzle_identifiers - 1}]\")\n",
    "\n",
    "print(f\"\\nOutput structure:\")\n",
    "print(f\"  logits: torch.Tensor of shape ({batch_size}, {seq_len}, {vocab_size})\")\n",
    "print(f\"    - unnormalized logits for each token position\")\n",
    "\n",
    "# ============================================================================\n",
    "# Create a dummy batch for testing\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING DUMMY BATCH FOR TESTING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dummy_batch = {\n",
    "    \"inputs\": torch.randint(0, vocab_size, (batch_size, seq_len), device=\"cuda\"),\n",
    "    \"labels\": torch.randint(0, vocab_size, (batch_size, seq_len), device=\"cuda\"),\n",
    "    \"puzzle_identifiers\": torch.randint(0, num_puzzle_identifiers, (batch_size,), device=\"cuda\"),\n",
    "}\n",
    "\n",
    "# print(f\"\\nDummy batch created:\")\n",
    "# for key, value in dummy_batch.items():\n",
    "#     print(f\"  {key}: {value.shape}, dtype={value.dtype}, device={value.device}\")\n",
    "\n",
    "# # Initialize carry\n",
    "# print(\"\\nInitializing carry...\")\n",
    "# with torch.device(\"cuda\"):\n",
    "#     with torch.no_grad():\n",
    "#         carry = model.initial_carry(dummy_batch)\n",
    "#         print(f\"Carry initialized: {type(carry)}\")\n",
    "#         print(f\"  inner_carry.z_H: {carry.inner_carry.z_H.shape}\")\n",
    "#         print(f\"  inner_carry.z_L: {carry.inner_carry.z_L.shape}\")\n",
    "#         print(f\"  steps: {carry.steps.shape}\")\n",
    "#         print(f\"  halted: {carry.halted.shape}\")\n",
    "\n",
    "# # Run one forward pass\n",
    "# print(\"\\nRunning forward pass...\")\n",
    "# with torch.no_grad():\n",
    "#     carry, loss, metrics, preds, all_finish = model(\n",
    "#         carry=carry,\n",
    "#         batch=dummy_batch,\n",
    "#         return_keys=[\"logits\"]\n",
    "#     )\n",
    "    \n",
    "# print(f\"\\nForward pass complete!\")\n",
    "# print(f\"  loss: {loss.item():.4f}\")\n",
    "# print(f\"  all_finish: {all_finish}\")\n",
    "# print(f\"  logits shape: {preds['logits'].shape}\")\n",
    "# print(f\"  metrics: {list(metrics.keys())}\")\n",
    "\n",
    "# # Get predictions\n",
    "# pred_tokens = torch.argmax(preds['logits'], dim=-1)\n",
    "# print(f\"  predicted tokens shape: {pred_tokens.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"READY FOR INSPECTION!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nAvailable objects:\")\n",
    "print(\"  - model: the full model (ACTLossHead)\")\n",
    "print(\"  - model.model: the ACT wrapper\")\n",
    "print(\"  - model.model.inner: the inner transformer model\")\n",
    "print(\"  - full_config: the full training config\")\n",
    "print(\"  - model_cfg: the model config\")\n",
    "print(\"  - dummy_batch: a sample batch\")\n",
    "print(\"  - carry: the model's recurrent state\")\n",
    "print(\"  - preds: predictions from forward pass\")\n",
    "print(\"\\nUseful inspection functions:\")\n",
    "print(\"  - inspect_model_structure(model): detailed layer breakdown\")\n",
    "print(\"  - inspect_state_dict(model): all parameter shapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32da5af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTLossHead(\n",
       "  (model): TinyRecursiveReasoningModel_ACTV1(\n",
       "    (inner): TinyRecursiveReasoningModel_ACTV1_Inner(\n",
       "      (embed_tokens): CastedEmbedding()\n",
       "      (lm_head): CastedLinear()\n",
       "      (q_head): CastedLinear()\n",
       "      (puzzle_emb): CastedSparseEmbedding()\n",
       "      (L_level): TinyRecursiveReasoningModel_ACTV1ReasoningModule(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TinyRecursiveReasoningModel_ACTV1Block(\n",
       "            (mlp_t): SwiGLU(\n",
       "              (gate_up_proj): CastedLinear()\n",
       "              (down_proj): CastedLinear()\n",
       "            )\n",
       "            (mlp): SwiGLU(\n",
       "              (gate_up_proj): CastedLinear()\n",
       "              (down_proj): CastedLinear()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ff715ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 81]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from puzzle_dataset import PuzzleDataset, PuzzleDatasetConfig\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def get_sudoku_embedding(model: torch.nn.Module,\n",
    "                         dataset_path: str = \"/home/zakarianarjis/workspace/TinyRecursiveModels/data/sudoku-extreme-1k-aug-1000\"):\n",
    "    \"\"\"\n",
    "    Loads one sample from the Sudoku dataset and returns the combined input embedding\n",
    "    (token embeddings + puzzle embeddings) suitable for the ACT model.\n",
    "    \"\"\"\n",
    "    # Minimal config compatible with PuzzleDataset\n",
    "    dataset_config = PuzzleDatasetConfig(\n",
    "        seed=42,\n",
    "        dataset_paths=[dataset_path],\n",
    "        rank=0,\n",
    "        num_replicas=1,\n",
    "        epochs_per_iter=1,\n",
    "        batch_size=1,\n",
    "        test_set_mode=False,\n",
    "        global_batch_size=1\n",
    "    )\n",
    "\n",
    "    # Load dataset and dataloader\n",
    "    dataset = PuzzleDataset(dataset_config, split=\"train\")\n",
    "    dataloader = DataLoader(dataset, batch_size=None)  # batch_size=None for iterable datasets\n",
    "\n",
    "    # Take the first sample\n",
    "    batch = next(iter(dataloader))\n",
    "    sample_dict = batch[1]  # the dict with 'inputs', 'labels', 'puzzle_identifiers'\n",
    "\n",
    "    token_ids = sample_dict['inputs'].cuda()                 # [seq_len]\n",
    "    puzzle_ids = sample_dict['puzzle_identifiers'].cuda()    # [num_puzzle_identifiers]\n",
    "\n",
    "    # Ensure batch dimension\n",
    "    token_ids = token_ids  # [1, seq_len]\n",
    "    puzzle_ids = puzzle_ids.unsqueeze(0) # [1, num_puzzle_identifiers]\n",
    "    print(token_ids.shape, puzzle_ids.shape)\n",
    "    # --- Construct combined embedding ---\n",
    "    # This uses the _input_embeddings method which handles puzzle embeddings internally\n",
    "    full_input_embed = model.model.inner._input_embeddings(\n",
    "        token_ids, puzzle_identifiers=puzzle_ids\n",
    "    )  # [1, seq_len + puzzle_emb_len, hidden_size]\n",
    "\n",
    "    return full_input_embed.squeeze(0), token_ids.squeeze(0)  # [seq_len + puzzle_emb_len, hidden_size], [seq_len]\n",
    "\n",
    "model.eval()\n",
    "embedding, ids = get_sudoku_embedding(model, dataset_path=\"/home/zakarianarjis/workspace/TinyRecursiveModels/data/sudoku-extreme-1k-aug-1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "606e316d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([97, 512])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f3eaaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test L_level with dummy input\n",
    "import torch\n",
    "\n",
    "L_level = model.model.inner.L_level\n",
    "hidden_size = model_cfg[\"hidden_size\"]\n",
    "seq_len_with_emb = model_cfg[\"seq_len\"] + model.model.inner.puzzle_emb_len\n",
    "batch_size_test = 1\n",
    "\n",
    "hidden_states = 2 * torch.randn(batch_size_test, seq_len_with_emb, hidden_size, device=\"cuda\", dtype=torch.bfloat16) \n",
    "input_injection = embedding.clone()\n",
    "cos_sin = model.model.inner.rotary_emb() if hasattr(model.model.inner, 'rotary_emb') else None\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output_1 = L_level(hidden_states=hidden_states ,cos_sin=cos_sin)\n",
    "#     output_2 = L_level(hidden_states=output_1 ,cos_sin=cos_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fdac28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2207, -0.0723,  0.4297,  ..., -0.3320, -0.1484, -0.1719],\n",
      "         [-0.0996, -0.0889,  0.3516,  ..., -0.0938, -0.0391, -0.1680],\n",
      "         [ 0.0195, -0.0391, -0.1924,  ...,  0.0073, -0.0059, -0.0039],\n",
      "         ...,\n",
      "         [ 0.1406,  0.1094, -0.1172,  ...,  0.1758,  0.0195,  0.0547],\n",
      "         [-0.0117,  0.0195, -0.1309,  ...,  0.0859,  0.0742, -0.2031],\n",
      "         [-0.0449, -0.0938,  0.0469,  ...,  0.1328, -0.1367,  0.1602]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "output = hidden_states.clone() + input_injection\n",
    "for i in range(10):\n",
    "    previous_output = output.clone()\n",
    "    with torch.no_grad():\n",
    "        output = L_level(hidden_states=output, cos_sin=cos_sin)  \n",
    "print(output-previous_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a7bd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "def _find_multiple(a, b):\n",
    "    return (-(a // -b)) * b\n",
    "a= 1365\n",
    "b = 256\n",
    "print(_find_multiple(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARC/pass@1: 0.42875\n",
    "# ARC/pass@2: 0.47625\n",
    "# ARC/pass@5: 0.50250\n",
    "# ARC/pass@10: 0.53375\n",
    "# ARC/pass@100: 0.60625\n",
    "# ARC/pass@1000: 0.61125"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
